{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Read in AP Data\n",
    "df_ap = spark.read.csv('ap_data/18676_data_sample2.csv', header=True, inferSchema=True, sep=\",\", nullValue=\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col, trim\n",
    "# Fix Column Name Formatting\n",
    "df_ap = df_ap.toDF(*(c.replace('.', '') for c in df_ap.columns)) \n",
    "# Get null value count for each column\n",
    "df_ap.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_ap.columns]).toPandas() "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   customer  id  erm__serial_number  AP Client Count Average  \\\n",
       "0         0   0                   0                        0   \n",
       "\n",
       "   AP Client Count Rate Average  AP Client Count Std Dev  \\\n",
       "0                             0                        0   \n",
       "\n",
       "   AP Client Count Total  AP Client Count Count  AP Client Count Max  \\\n",
       "0                      0                      0                  126   \n",
       "\n",
       "   5 GHz Client Count Average  ...  Unique Clients  Average TX Kbps  \\\n",
       "0                         126  ...           99999            99999   \n",
       "\n",
       "   Average RX Kbps  Average Total Kbps   Average Total RSSI  \\\n",
       "0            99999                99999               99999   \n",
       "\n",
       "   Average Total SNR  Average Total MCS  Average Total Bandwidth  \\\n",
       "0              99999              99999                    99999   \n",
       "\n",
       "   Average Total LinkQuality  Average Total TxReties  \n",
       "0                      99999                   99999  \n",
       "\n",
       "[1 rows x 853 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>id</th>\n",
       "      <th>erm__serial_number</th>\n",
       "      <th>AP Client Count Average</th>\n",
       "      <th>AP Client Count Rate Average</th>\n",
       "      <th>AP Client Count Std Dev</th>\n",
       "      <th>AP Client Count Total</th>\n",
       "      <th>AP Client Count Count</th>\n",
       "      <th>AP Client Count Max</th>\n",
       "      <th>5 GHz Client Count Average</th>\n",
       "      <th>...</th>\n",
       "      <th>Unique Clients</th>\n",
       "      <th>Average TX Kbps</th>\n",
       "      <th>Average RX Kbps</th>\n",
       "      <th>Average Total Kbps</th>\n",
       "      <th>Average Total RSSI</th>\n",
       "      <th>Average Total SNR</th>\n",
       "      <th>Average Total MCS</th>\n",
       "      <th>Average Total Bandwidth</th>\n",
       "      <th>Average Total LinkQuality</th>\n",
       "      <th>Average Total TxReties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 853 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Drop Columns with all null values\n",
    "def drop_null_columns(df):\n",
    "    \n",
    "    _df_length = df.count()\n",
    "    null_counts = df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).collect()[0].asDict()\n",
    "    to_drop = [k for k, v in null_counts.items() if v >= _df_length]\n",
    "    df = df.drop(*to_drop)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_ap = drop_null_columns(df_ap)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Read in Wifi-Data\n",
    "df_wifi = spark.read.csv('Wifi_CIR/WiFi_CIR_February_2021.csv', header=True, inferSchema=True, sep=\",\", nanValue='', nullValue='')\n",
    "\n",
    "# Replace 'No' with None\n",
    "df_wifi = df_wifi.na.replace('No', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Update serial number column name before merging both data frames\n",
    "df_ap = df_ap.withColumnRenamed('erm__serial_number', 'SERIAL_NO')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "max_columns = [c for c in df_ap.columns if 'Max' in c]\n",
    "average_columns = [c for c in df_ap.columns if 'Average' in c]\n",
    "rate_average_columns = [c for c in df_ap.columns if 'Rate Average' in c]\n",
    "std_columns = [c for c in df_ap.columns if 'Std Dev' in c]\n",
    "total_columns = [c for c in df_ap.columns if 'Total' in c]\n",
    "count_columns = [c for c in df_ap.columns if 'Count' in c]\n",
    "count_average = [c for c in df_ap.columns if 'Count Average' in c]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Drop columns from wifi data\n",
    "columns_to_drop = df_wifi.columns + ['customer', 'id'] + total_columns + count_columns + rate_average_columns \n",
    "columns_to_drop.remove('SERIAL_NO')\n",
    "[columns_to_drop.remove(c) for c in count_average]\n",
    "\n",
    "# Merge dataframes based on 'SERIAL_NO' column and add 'label' column where 1 represents a call-in\n",
    "df = df_ap.join(df_wifi.withColumn('label', F.lit(1)), 'SERIAL_NO', 'left').fillna(0).drop(*columns_to_drop)\n",
    "df.groupBy('label').count().show() "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|  519|\n",
      "|    0|99563|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "maxes = [df.agg({c: \"max\"}).collect()[0][0] for c in df.columns[1:-1]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "mins = [df.agg({c: \"min\"}).collect()[0][0] for c in df.columns[1:-1]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "averages = [df.agg({c: \"avg\"}).collect()[0][0] for c in df.columns[1:-1]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "import csv\n",
    "fields = ['feauture', 'min', 'max', 'avg']\n",
    "rows = [mins, maxes, averages]\n",
    "\n",
    "filename = \"AP_WiFi_Features.csv\"\n",
    "    \n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "\n",
    "    # writing the fields \n",
    "    csvwriter.writerow(fields) \n",
    "\n",
    "    for count in range(len(maxes)):\n",
    "        #writing the data rows \n",
    "        csvwriter.writerow([df.columns[1:-1][count], rows[0][count], rows[1][count], rows[2][count]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}